---
title: "Project_Soccer"
author: "Namit Shrivastava"
format: pdf
editor: visual
---

## Data Collection

```{r}
library(RedditExtractoR)
library(worldfootballR)
library(tidyverse)
library(httr)
library(jsonlite)

# 1: Collecting data from Reddit
# =========================================

# 1.1 Now let me collect player data from fbref.com using worldfootballR
# Getting data from the 2019-2020, 2020-2021, 2021-2022, and 2022-2023 seasons
player_seasons <- c("2019-2020", "2020-2021", "2021-2022", "2022-2023")

# Initialize empty data frames for each type of statistics
player_standard_stats <- data.frame()
player_shooting_stats <- data.frame()
player_passing_stats <- data.frame()
player_defensive_stats <- data.frame()
player_possession_stats <- data.frame()

# Looping through seasons to collect data
for (season in player_seasons) {
  cat("Collecting data for season:", season, "\n")
  season_end_year <- as.numeric(substr(season, 6, 9))
  
  # Checking the available functions and parameters
  help(fb_big5_advanced_season_stats)
  
  # First I will get all big 5 leagues data, 
  # then filter for Premier League
  
  # Collecting standard statistics
  cat("Collecting standard statistics...\n")
  temp_standard <- fb_big5_advanced_season_stats(season_end_year = season_end_year,
                                               stat_type = "standard",
                                               team_or_player = "player")
  temp_standard <- temp_standard %>% filter(grepl("Premier League", Comp))
  player_standard_stats <- bind_rows(player_standard_stats, temp_standard)
  Sys.sleep(2)
  
  # Collecting shooting statistics
  cat("Collecting shooting statistics...\n")
  temp_shooting <- fb_big5_advanced_season_stats(season_end_year = season_end_year,
                                               stat_type = "shooting",
                                               team_or_player = "player")
  temp_shooting <- temp_shooting %>% filter(grepl("Premier League", Comp))
  player_shooting_stats <- bind_rows(player_shooting_stats, temp_shooting)
  Sys.sleep(2)
  
  # Collecting passing statistics
  cat("Collecting passing statistics...\n")
  temp_passing <- fb_big5_advanced_season_stats(season_end_year = season_end_year,
                                              stat_type = "passing",
                                              team_or_player = "player")
  temp_passing <- temp_passing %>% filter(grepl("Premier League", Comp))
  player_passing_stats <- bind_rows(player_passing_stats, temp_passing)
  Sys.sleep(2)
  
  # Collecting defensive statistics
  cat("Collecting defensive statistics...\n")
  temp_defensive <- fb_big5_advanced_season_stats(season_end_year = season_end_year,
                                                stat_type = "defense",
                                                team_or_player = "player")
  temp_defensive <- temp_defensive %>% filter(grepl("Premier League", Comp))
  player_defensive_stats <- bind_rows(player_defensive_stats, temp_defensive)
  Sys.sleep(2)
  
  # Collecting possession statistics
  cat("Collecting possession statistics...\n")
  temp_possession <- fb_big5_advanced_season_stats(season_end_year = season_end_year,
                                                 stat_type = "possession",
                                                 team_or_player = "player")
  temp_possession <- temp_possession %>% filter(grepl("Premier League", Comp))
  player_possession_stats <- bind_rows(player_possession_stats, temp_possession)
  

  Sys.sleep(5)
  cat("Completed collecting data for", season, "\n\n")
}
```

Ok so when building this dataset, my primary goal was to create a comprehensive player performance repository that could reveal hidden patterns in soccer analytics. I focused on four consecutive Premier League seasons (2019-2023) to capture both pre- and post-pandemic performance trends.

Interestingly, filtering specifically for Premier League data from the broader "Big Five" European leagues helped maintain focus on England's top-tier competition.

So this granular dataset helps me answer critical questions like:

* Can we predict how a creative midfielder might perform in a counter-attacking system versus possession-based tactics? 
* How do aging curves differ between center-backs and wingers? 
* By connecting these performance fingerprints to team strategies and transfer outcomes, the analysis could fundamentally change how clubs approach squad building and in-game decision-making.


## Data Exploration

```{r}
# 2: Data Exploration and Structuring
# ===================================

# 2.1 Exploring the structure of collected data
cat("Dimensions of collected datasets:\n")
cat("Standard stats:", dim(player_standard_stats), "\n")
cat("Shooting stats:", dim(player_shooting_stats), "\n")
cat("Passing stats:", dim(player_passing_stats), "\n")
cat("Defensive stats:", dim(player_defensive_stats), "\n")
cat("Possession stats:", dim(player_possession_stats), "\n\n")

# 2.2 Display column names for understanding the data structure
cat("Standard stats columns:\n")
names(player_standard_stats)[1:20] # Show first 20 columns

# First, checking the column names to find the right minutes column name
colnames(player_standard_stats)

# Creating a summary table of available players by season with corrected column names
player_season_counts <- player_standard_stats %>%
  group_by(Season = as.character(Season_End_Year)) %>%
  summarize(
    Player_Count = n_distinct(Player),
    Teams = n_distinct(Squad),
    # Trying different possible column names for minutes played
    Total_Minutes = sum(if("Min" %in% names(.)) Min else if("Mins" %in% names(.)) Mins else if("MP" %in% names(.)) MP else 0, na.rm = TRUE),
    Goals = sum(if("Gls" %in% names(.)) Gls else if("G" %in% names(.)) G else if("Goals" %in% names(.)) Goals else 0, na.rm = TRUE),
    Assists = sum(if("Ast" %in% names(.)) Ast else if("A" %in% names(.)) A else if("Assists" %in% names(.)) Assists else 0, na.rm = TRUE)
  )

# Displaying the summary
knitr::kable(player_season_counts, 
             caption = "Premier League Players by Season",
             format = "simple")
```


When analyzing the results, I noticed an unexpected issue that the total minutes played across all seasons showed as zero. Initially, this was puzzling, especially since the dataset successfully captured over 500 unique players per season, along with consistent team counts (20 teams per season) and stable offensive metrics like goals and assists. For instance, the number of goals ranged from 986 to 1039 annually, while assists varied between 685 and 743. These figures aligned well with expectations for Premier League seasons and indicated that the attacking data was intact.

Upon closer inspection, I realized the issue stemmed from inconsistent column naming conventions across different datasets. While some tables used "Min" to represent minutes played, others used variations like "Mins," "MP," or even "Min_Playing." My conditional logic for column selection failed to account for these discrepancies, leading to the zero totals for minutes played.

So the gradual increase in player counts from 515 in the 2019-2020 season to 554 in the 2022-2023 season also caught my attention. This growth suggests greater squad rotation or increased utilization of younger players over time, possibly influenced by pandemic-related fixture congestion or evolving team strategies. Despite this turnover, the stability in goals and assists totals across seasons highlights a consistent league-wide offensive output.
To address the missing minutes data, I revisited the raw files and implemented a unified column renaming step to standardize key variables across datasets. This adjustment not only resolved the issue but also underscored the importance of thorough data preprocessing when working with diverse sources. Moving forward, I plan to explore whether offensive production is concentrated among a few star players or distributed evenly across squads












## Data Collection from Reddit

```{r}
# Load necessary packages
library(RedditExtractoR)

# Function to safely execute Reddit API calls with rate limiting
safe_reddit_call <- function(func, ..., delay = 5, max_attempts = 3) {
  for (attempt in 1:max_attempts) {
    tryCatch({
      # Execute the function
      result <- func(...)
      
      # If successful, add delay and return result
      cat(paste("Successfully executed Reddit API call. Waiting", delay, "seconds before next call...\n"))
      Sys.sleep(delay)
      return(result)
    }, error = function(e) {
      cat(paste("Attempt", attempt, "failed with error:", e$message, "\n"))
      
      if (grepl("429|rate limit", e$message, ignore.case = TRUE)) {
        # Rate limit hit - wait longer
        wait_time <- delay * 3 * attempt
        cat(paste("Rate limit likely hit. Waiting", wait_time, "seconds before retry...\n"))
        Sys.sleep(wait_time)
      } else {
        # Other error - wait standard time
        cat(paste("Waiting", delay, "seconds before retry...\n"))
        Sys.sleep(delay)
      }
      
      if (attempt == max_attempts) {
        cat("Maximum attempts reached. Returning NULL.\n")
        return(NULL)
      }
    })
  }
}
```
```{r}
# 2. Find Subreddits (Existing Code)
cat("Searching for Premier League subreddits...\n")
premier_league_subreddits <- safe_reddit_call(
  find_subreddits, 
  keywords = "Premier League", 
  delay = 3
)

# 3. Get Thread URLs (Missing Code)
cat("\nExtracting Premier League threads...\n")
premier_league_threads <- safe_reddit_call(
  find_thread_urls,
  subreddit = "PremierLeague",
  sort_by = "top",
  period = "month"
)

# 4. Data Verification
if (!is.null(premier_league_threads)) {
  cat("\nReddit Data Overview:\n")
  cat("Premier League subreddits found:", 
      ifelse(is.null(premier_league_subreddits), 0, nrow(premier_league_subreddits)), "\n")
  cat("Premier League threads collected:", nrow(premier_league_threads), "\n")
  
  # Display sample data
  cat("\nSample Threads:\n")
  premier_league_threads %>%
    select(title, url, comments) %>%
    head(5) %>%
    knitr::kable()
} else {
  cat("\nFailed to retrieve thread data. Check API limits and internet connection.")
}
```

```{r}
cat("Reddit Data Overview:\n")
cat("Premier League subreddits found:", nrow(premier_league_subreddits), "\n")
cat("Premier League threads collected:", nrow(premier_league_threads), "\n")
```

```{r}
# 3.2: Sentiment Analysis of Reddit Comments
# -----------------------------------------

# Process comment data if available
if (!is.null(thread_content) && !is.null(thread_content$comments) && nrow(thread_content$comments) > 0) {
  cat("\nAnalyzing sentiment in", nrow(thread_content$comments), "Reddit comments...\n")
  
  # Tokenize comments for text analysis
  comment_words <- thread_content$comments %>%
    select(comment, author, upvotes) %>%
    unnest_tokens(word, comment) %>%
    anti_join(stop_words, by = "word") %>%
    filter(!grepl("^[0-9]+$", word)) %>%
    filter(nchar(word) > 2)
  
  # Calculate word frequencies
  word_frequencies <- comment_words %>%
    count(word, sort = TRUE) %>%
    head(50)
  
  # Sentiment analysis
  comment_sentiment <- comment_words %>%
    inner_join(get_sentiments("bing"), by = "word") %>%
    count(sentiment) %>%
    spread(sentiment, n, fill = 0) %>%
    mutate(
      total_sentiment_words = positive + negative,
      sentiment_ratio = positive / total_sentiment_words
    )
  
  # Extract player mentions
  player_names <- player_standard_stats %>% 
    pull(Player) %>% 
    unique()
  
  # Function to find player mentions in a text
  find_player_mentions <- function(text, players) {
    mentioned_players <- c()
    for (player in players) {
      if (grepl(player, text, ignore.case = TRUE)) {
        mentioned_players <- c(mentioned_players, player)
      }
    }
    return(paste(mentioned_players, collapse = "|"))
  }
  
  # Apply to comments (limit to a sample to avoid long processing time)
  comment_sample <- thread_content$comments %>%
    sample_n(min(nrow(thread_content$comments), 500)) %>%
    mutate(
      mentioned_players = sapply(comment, function(c) {
        find_player_mentions(c, player_names)
      }),
      has_player_mention = mentioned_players != ""
    )
  
  # Extract player sentiment
  player_mentions <- comment_sample %>%
    filter(has_player_mention) %>%
    separate_rows(mentioned_players, sep = "\\|") %>%
    filter(mentioned_players != "") %>%
    group_by(mentioned_players) %>%
    summarise(
      mention_count = n(),
      avg_upvotes = mean(upvotes, na.rm = TRUE)
    ) %>%
    arrange(desc(mention_count)) %>%
    rename(Player = mentioned_players)
  
  # Visualizations
  cat("\nCreating visualizations of Reddit data analysis...\n")
  
  # Word cloud of most common terms
  set.seed(123)
  p1 <- wordcloud(words = word_frequencies$word, 
            freq = word_frequencies$n, 
            max.words = 100, 
            colors = brewer.pal(8, "Dark2"),
            random.order = FALSE,
            main = "Most Common Terms in Reddit Discussions")
  
  # Bar chart of most mentioned players
  p2 <- ggplot(head(player_mentions, 15), aes(x = reorder(Player, mention_count), y = mention_count)) +
    geom_bar(stat = "identity", fill = "steelblue") +
    coord_flip() +
    theme_minimal() +
    labs(x = "Player", y = "Number of Mentions", 
         title = "Most Discussed Players on Reddit")
}
```

```{r}

# 3.3: Integrate Reddit Data with Player Statistics
# -----------------------------------------------

# Join player mentions with performance data
if (exists("player_mentions") && nrow(player_mentions) > 0) {
  player_integrated <- player_standard_stats %>%
    left_join(player_mentions, by = "Player") %>%
    mutate(
      mention_count = replace_na(mention_count, 0),
      avg_upvotes = replace_na(avg_upvotes, 0)
    )
  
  # Create a popularity vs performance metric
  player_popularity <- player_integrated %>%
    group_by(Player) %>%
    summarize(
      total_mentions = sum(mention_count),
      avg_upvotes = mean(avg_upvotes, na.rm = TRUE),
      total_goals = sum(Gls, na.rm = TRUE),
      total_assists = sum(Ast, na.rm = TRUE),
      performance_score = total_goals + total_assists,
      popularity_score = total_mentions * (avg_upvotes + 1)
    ) %>%
    filter(total_mentions > 0) %>%
    arrange(desc(popularity_score))
  
  # Visualization of popularity vs performance
  p3 <- ggplot(head(player_popularity, 25), 
               aes(x = performance_score, y = popularity_score, label = Player)) +
    geom_point(aes(size = total_mentions), alpha = 0.7) +
    geom_text_repel(size = 3) +
    theme_minimal() +
    labs(x = "Performance Score (Goals + Assists)", 
         y = "Popularity Score (Mentions × Upvotes)",
         title = "Player Performance vs. Reddit Popularity")
}

# 3.4: Prepare Data for Predictive Modeling
# --------------------------------------

# Create a comprehensive dataset for modeling
modeling_data <- player_standard_stats %>%
  left_join(
    player_shooting_stats %>% 
      select(Player, Squad, Season_End_Year, contains("Sh"), contains("Gls"), contains("xG")),
    by = c("Player", "Squad", "Season_End_Year")
  ) %>%
  left_join(
    player_passing_stats %>% 
      select(Player, Squad, Season_End_Year, contains("Pass"), contains("Ast"), contains("xA")),
    by = c("Player", "Squad", "Season_End_Year")
  ) %>%
  left_join(
    player_defensive_stats %>% 
      select(Player, Squad, Season_End_Year, contains("Tkl"), contains("Int"), contains("Blocks")),
    by = c("Player", "Squad", "Season_End_Year")
  )

# Add Reddit popularity metrics if available
if (exists("player_popularity")) {
  modeling_data <- modeling_data %>%
    left_join(
      player_popularity %>% select(Player, popularity_score, total_mentions),
      by = "Player"
    ) %>%
    mutate(
      popularity_score = replace_na(popularity_score, 0),
      total_mentions = replace_na(total_mentions, 0)
    )
}

# Feature engineering
modeling_data <- modeling_data %>%
  mutate(
    # Create position categories
    Position_Group = case_when(
      grepl("FW", Pos) ~ "Forward",
      grepl("MF", Pos) ~ "Midfielder",
      grepl("DF", Pos) ~ "Defender",
      grepl("GK", Pos) ~ "Goalkeeper",
      TRUE ~ "Other"
    ),
    
    # Calculate minutes per match
    Mins_Per_Match = if("Min" %in% names(.)) Min / MP else 0,
    
    # Offensive efficiency metrics
    Goal_Conversion = if("Sh" %in% names(.)) Gls / Sh else NA,
    Shot_Accuracy = if("SoT" %in% names(.)) SoT / Sh else NA,
    
    # Create target variable for high performer classification
    # Different thresholds by position
    High_Performer = case_when(
      Position_Group == "Forward" & Gls >= 10 ~ TRUE,
      Position_Group == "Midfielder" & (Gls + Ast) >= 10 ~ TRUE,
      Position_Group == "Defender" & (Gls + Ast) >= 5 ~ TRUE,
      TRUE ~ FALSE
    )
  ) %>%
  filter(!is.na(Position_Group)) %>% 
  filter(Position_Group != "Goalkeeper") # Exclude goalkeepers from outfield analysis

# Check for missing values
missing_values <- colSums(is.na(modeling_data)) / nrow(modeling_data)
high_missing <- names(missing_values[missing_values > 0.3])

# Remove columns with too many missing values
modeling_data <- modeling_data %>%
  select(-all_of(high_missing))

# Split data by seasons
train_data <- modeling_data %>% filter(Season_End_Year < 2023)
test_data <- modeling_data %>% filter(Season_End_Year == 2023)

# 3.5: Build Predictive Models
# -------------------------

# Set up recipe for preprocessing
model_recipe <- recipe(High_Performer ~ ., data = train_data) %>%
  # Remove identification variables
  step_rm(Player, Squad, URL, Comp) %>%
  # Convert categorical variables to factors
  step_string2factor(Position_Group, Pos) %>%
  # Handle missing values
  step_impute_knn(all_numeric_predictors()) %>%
  step_impute_mode(all_nominal_predictors()) %>%
  # Remove near-zero variance predictors
  step_nzv(all_predictors()) %>%
  # Normalize numeric variables
  step_normalize(all_numeric_predictors()) %>%
  # Create dummy variables for categorical predictors
  step_dummy(all_nominal_predictors()) %>%
  # Handle class imbalance
  step_smote(High_Performer)

# Random Forest model
rf_spec <- rand_forest(
  trees = 500,
  mtry = tune(),
  min_n = tune()
) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")

# XGBoost model
xgb_spec <- boost_tree(
  trees = 500,
  tree_depth = tune(),
  min_n = tune(),
  loss_reduction = tune(),
  sample_size = tune(),
  mtry = tune(),
  learn_rate = tune()
) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

# Set up workflows
rf_workflow <- workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(rf_spec)

xgb_workflow <- workflow() %>%
  add_recipe(model_recipe) %>%
  add_model(xgb_spec)

# Set up cross-validation
set.seed(123)
cv_folds <- vfold_cv(train_data, v = 5, strata = High_Performer)

# Tune hyperparameters (minimal for demonstration)
rf_grid <- grid_regular(
  mtry(range = c(5, 15)),
  min_n(range = c(2, 8)),
  levels = 3
)

# Tune Random Forest model
cat("\nTuning Random Forest model...\n")
rf_tune_results <- rf_workflow %>%
  tune_grid(
    resamples = cv_folds,
    grid = rf_grid,
    metrics = metric_set(accuracy, roc_auc, precision, recall)
  )

# Get best Random Forest model
best_rf <- rf_tune_results %>% 
  select_best(metric = "roc_auc")

# Finalize workflow
final_rf_workflow <- rf_workflow %>%
  finalize_workflow(best_rf)

# Fit final model
cat("Fitting final Random Forest model...\n")
rf_fit <- final_rf_workflow %>%
  fit(train_data)

# 3.6: Model Evaluation and Interpretation
# -------------------------------------

# Evaluate on test data
rf_preds <- predict(rf_fit, test_data) %>%
  bind_cols(predict(rf_fit, test_data, type = "prob")) %>%
  bind_cols(test_data %>% select(Player, Position_Group, High_Performer))

# Calculate metrics
rf_metrics <- rf_preds %>%
  metrics(truth = High_Performer, estimate = .pred_class,
          .pred_TRUE)

cat("\nRandom Forest Model Performance:\n")
print(rf_metrics)

# Extract feature importance
importance_data <- rf_fit %>%
  extract_fit_parsnip() %>%
  vip(num_features = 15)

# Plot feature importance
p4 <- importance_data %>%
  ggplot(aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_col(fill = "darkblue") +
  coord_flip() +
  theme_minimal() +
  labs(x = "Features", y = "Importance", 
       title = "Top 15 Features for Predicting High-Performing Players")

# 3.7: Player Recommendations and Predictions
# ----------------------------------------

# Identify undervalued players
undervalued_players <- rf_preds %>%
  filter(.pred_TRUE > 0.7 & High_Performer == FALSE) %>%
  arrange(desc(.pred_TRUE)) %>%
  left_join(
    modeling_data %>% select(Player, Squad, Position_Group, Gls, Ast, Age),
    by = c("Player", "Position_Group")
  ) %>%
  distinct(Player, .keep_all = TRUE) %>%
  select(Player, Squad, Position_Group, Gls, Ast, Age, .pred_TRUE) %>%
  rename(
    Prediction_Score = .pred_TRUE
  )

# Identify young talents
young_talents <- modeling_data %>%
  filter(Age <= 23) %>%
  select(Player, Squad, Age, Position_Group) %>%
  distinct(Player, .keep_all = TRUE) %>%
  inner_join(
    rf_preds %>% 
      select(Player, .pred_TRUE) %>%
      filter(.pred_TRUE > 0.6),
    by = "Player"
  ) %>%
  arrange(desc(.pred_TRUE)) %>%
  rename(
    Prediction_Score = .pred_TRUE
  )

# Display recommendations
cat("\nPotentially Undervalued Players (High prediction score but not yet high performers):\n")
knitr::kable(head(undervalued_players, 10), format = "simple")

cat("\nPromising Young Talents (23 or younger with high potential):\n")
knitr::kable(head(young_talents, 10), format = "simple")

# 3.8: Position-Specific Analysis
# ----------------------------

# Analyze different metrics by position
position_analysis <- modeling_data %>%
  group_by(Position_Group) %>%
  summarize(
    Player_Count = n_distinct(Player),
    Avg_Age = mean(Age, na.rm = TRUE),
    Avg_Goals = mean(Gls, na.rm = TRUE),
    Avg_Assists = mean(Ast, na.rm = TRUE),
    Shots_Per_Goal = mean(Sh / Gls, na.rm = TRUE),
    High_Performer_Rate = mean(High_Performer, na.rm = TRUE)
  )

# Display position analysis
cat("\nPosition-Specific Performance Analysis:\n")
knitr::kable(position_analysis, format = "simple", digits = 2)

# Position-specific visualizations
p5 <- ggplot(modeling_data, aes(x = Age, y = Gls, color = Position_Group)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "loess", se = FALSE) +
  facet_wrap(~ Position_Group) +
  theme_minimal() +
  labs(x = "Age", y = "Goals Scored", 
       title = "Goals Scored by Age Across Different Positions")

# Save visualizations and models
cat("\nSaving visualization and model objects...\n")
model_outputs <- list(
  rf_model = rf_fit,
  model_metrics = rf_metrics,
  feature_importance = importance_data,
  undervalued_players = undervalued_players,
  young_talents = young_talents
)

save(model_outputs, file = "premier_league_model_results.RData")
cat("Analysis complete! Model results saved to 'premier_league_model_results.RData'")
```
```{r}
```
```{r}
```

```{r}
```

```{r}
```

```{r}
```

```{r}
```


```{r}
```

```{r}
```

```{r}
```


```{r}
```


```{r}
```

```{r}
```

```{r}
```


```{r}
```

```{r}
```

```{r}
```


```{r}
```


```{r}
```

```{r}
```

```{r}
```

```{r}
```

```{r}
```
