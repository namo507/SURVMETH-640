---
title: "English Premier League (1992/93 - 2021/22) Spending Analysis and Predictions for the next 20 years"
author: "Namit Shrivastava"
date: "2024-04-13"
format: pdf
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
installed.packages(c("tidyverse"))
```

## Data Extraction

```{r}
# Loading necessary libraries
library(rvest)
library(httr)
library(tidyverse)
library(jsonlite)
library(tidyjson)
library(dplyr)

# Function to scrape transfer data for a given season
scrape_transfer_data <- function(season) {
  
  url <- sprintf("https://www.transfermarkt.co.uk/premier-league/transfers/wettbewerb/GB1/saison_id/%d", season)
  cat("Scraping transfer data for season:", season, "\n")
  
  # Reading the page content
  page <- tryCatch({
    read_html(url)
  }, error = function(e) {
    cat("Error reading URL:", url, "\n")
    return(NULL)
  })
  
  if (is.null(page)) return(list())
  
  # Locating the table node (Transfermarkt usually labels it with class "items")
  table_node <- html_node(page, "table.items")
  if (is.na(table_node)) {
    cat("Transfer table not found for season:", season, "\n")
    return(list())
  }
  
  # Parse the table into a data frame (fill = TRUE handles missing cells)
  transfer_table <- html_table(table_node, fill = TRUE)
  
  # Format season as "1992/93", "1993/94", etc.
  formatted_season <- sprintf("%d/%s", season, substr(as.character(season + 1), 3, 4))
  
  # For demonstration, assume that the table has at least 5 columns where:
  # Column 2: Club, Column 3: Income, Column 4: Expense, Column 5: Balance.
  if (ncol(transfer_table) < 5) {
    cat("Not enough columns in transfer table for season:", season, "\n")
    return(list())
  }
  
  # Rename and select the columns of interest; adjust indices if necessary
  transfer_data <- transfer_table %>%
    rename(
      Club = 2,
      Income = 3,
      Expense = 4,
      Balance = 5
    ) %>%
    mutate(Season = formatted_season)
  
  # Convert each row to a list so that we can export a list of records
  records <- split(transfer_data, seq(nrow(transfer_data)))
  records <- lapply(records, as.list)
  
  return(records)
}

# Function to scrape the EPL league table data for a given season
scrape_epl_table <- function(season) {
  # Construct the URL for the league table
  url <- sprintf("https://www.transfermarkt.co.uk/premier-league/tabelle/wettbewerb/GB1/saison_id/%d", season)
  cat("Scraping league table data for season:", season, "\n")
  
  page <- tryCatch({
    read_html(url)
  }, error = function(e) {
    cat("Error reading URL:", url, "\n")
    return(NULL)
  })
  
  if (is.null(page)) return(list())
  
  table_node <- html_node(page, "table.items")
  if (is.na(table_node)) {
    cat("League table not found for season:", season, "\n")
    return(list())
  }
  
  league_table <- html_table(table_node, fill = TRUE)
  formatted_season <- sprintf("%d/%s", season, substr(as.character(season + 1), 3, 4))
  
  # Assume the league table has at least 9 columns where:
  # Column 1: Position, Column 2: Team, Column 3: Played, Column 4: Wins,
  # Column 5: Draws, Column 6: Losses and Column 9: Points.
  if (ncol(league_table) < 9) {
    cat("Not enough columns in league table for season:", season, "\n")
    return(list())
  }
  
  league_data <- league_table %>%
    rename(
      Position = 1,
      Team = 2,
      Played = 3,
      Wins = 4,
      Draws = 5,
      Losses = 6,
      Points = 9
    ) %>%
    mutate(Season = formatted_season)
  
  records <- split(league_data, seq(nrow(league_data)))
  records <- lapply(records, as.list)
  
  return(records)
}

# Main code to loop over seasons and assemble the data
transfer_data_all <- list()
epl_table_all <- list()
```

So firstly, I created two specialized functions to collect historical Premier League data from Transfermarkt. The first function, scrape_transfer_data(), extracts transfer information for each season by constructing the appropriate URL with the season parameter. I made sure to include error handling to gracefully manage any connection issues like the function attempts to read the webpage's HTML and looks specifically for tables with the "items" class that contain the transfer data. When it finds the right table, it parses the content and formats it properly, extracting club names, income, expenses, and balance figures.

My second function, scrape_epl_table(), works similarly but targets the final league standings. It grabs position information, team names, match statistics (played, wins, draws, losses), and point totals. For both functions, I format the season nicely (like "1992/93") and transform each row of data into a list format that will work well for JSON export. I also included thorough validation checks to ensure the tables contain the expected number of columns before processing them. This approach lets me build a comprehensive dataset spanning nearly three decades of Premier League history in a structured format that's ready for analysis.


```{r}
# Loop through each season from 1992/93 (season = 1992) to 2021/22 (season = 2021)
for (season in 1992:2021) {
  cat("Processing season:", season, "\n")
  
  # Scrape transfer data for the season
  transfers <- scrape_transfer_data(season)
  if (length(transfers) > 0) {
    transfer_data_all <- c(transfer_data_all, transfers)
  }
  Sys.sleep(2) 
  
  # Scrape league table data
  league_table <- scrape_epl_table(season)
  if (length(league_table) > 0) {
    epl_table_all <- c(epl_table_all, league_table)
  }
  Sys.sleep(2)
}
```

After creating the specialized scraping functions, I used this loop to process 30 seasons of Premier League data. For each season, I first called scrape_transfer_data() to extract the transfer information, then added the results to my growing collection if data was successfully retrieved.

I then followed the same pattern for the league table data, calling scrape_epl_table() for each season and adding the results to my collection. The conditional statements ensure I only append data when the scraping was successful. So this methodical approach allowed me to build a comprehensive dataset spanning the entire Premier League era from its inception in 1992/93 through the 2021/22 season.

## Overview

Ok so this analysis examines data from the English Premier League seasons 1992/92 through 2021/22 and my motive is to investigate the relationship between transfer spending and on-field success. The data was extracted from [Transfermarkt](https://www.transfermarkt.co.uk).

## Data Collection

```{r}
transfer_data_raw <- read_json(path = "Income_expense_raw_1992-2021.json")
epl_tables_raw <- read_json(path = "Epl_tables_raw_1992-2021.json")

parse_number_value <- function(v) {
  is_k <- str_detect(v, "k$")
  v <- parse_number(str_replace_all(str_trim(v), "[^0-9\\.]+", ""))
  if (is_k) {
    return(v * 0.001)
  }
  return(v)
}

normalise_club_name <- function(v) {
  v <- str_trim(v)
  if (v %in% c("Arsenal FC")) {
    return("Arsenal")
  } else if (v %in% c("AFC Bournemouth")) {
    return("Bournemouth")
  } else if(v %in% c("Barnsley FC")) {
    return("Barnsley")
  } else if(v %in% c("Birmingham")) {
    return("Birmingham City")
  } else if(v %in% c("Blackburn")) {
    return("Blackburn Rovers")
  } else if(v %in% c("Blackpool FC")) {
    return("Blackpool")
  } else if(v %in% c("Bolton")) {
    return("Bolton Wanderers")
  } else if(v %in% c("Bradford")) {
    return("Bradford City")
  } else if(v %in% c("Brentford FC")) {
    return("Brentford")
  } else if(v %in% c("Brighton")) {
    return("Brighton & Hove Albion")
  } else if(v %in% c("Burnley FC")) {
    return("Burnley")
  } else if(v %in% c("Cardiff")) {
    return("Cardiff City")
  } else if(v %in% c("Charlton")) {
    return("Charlton Athletic")
  } else if(v %in% c("Chelsea FC")) {
    return("Chelsea")
  } else if(v %in% c("Coventry")) {
    return("Coventry City")
  } else if(v %in% c("Derby")) {
    return("Derby County")
  } else if(v %in% c("Everton FC")) {
    return("Everton")
  } else if(v %in% c("Fulham FC")) {
    return("Fulham")
  } else if(v %in% c("Huddersfield")) {
    return("Huddersfield Town")
  } else if(v %in% c("Ipswich")) {
    return("Ipswich Town")
  } else if(v %in% c("Leeds")) {
    return("Leeds United")
  } else if(v %in% c("Leicester")) {
    return("Leicester City")
  } else if(v %in% c("Liverpool FC")) {
    return("Liverpool")
  } else if(v %in% c("Norwich FC", "Norwich")) {
    return("Norwich City")
  } else if(v %in% c("Man City")) {
    return("Manchester City")
  } else if(v %in% c("Man Utd")) {
    return("Manchester United")
  } else if(v %in% c("Middlesbrough FC")) {
    return("Middlesbrough")
  } else if(v %in% c("Newcastle")) {
    return("Newcastle United")
  } else if(v %in% c("Nottm Forest")) {
    return("Nottingham Forest")
  } else if(v %in% c("Portsmouth FC")) {
    return("Portsmouth")
  } else if(v %in% c("QPR")) {
    return("Queens Park Rangers")
  } else if(v %in% c("Reading FC")) {
    return("Reading")
  } else if(v %in% c("Sheff Utd")) {
    return("Sheffield United")
  } else if(v %in% c("Sheff Wed")) {
    return("Sheffield Wednesday")
  } else if(v %in% c("Southampton FC")) {
    return("Southampton")
  } else if(v %in% c("Sunderland AFC")) {
    return("Sunderland")
  } else if(v %in% c("Spurs")) {
    return("Tottenham Hotspur")
  } else if(v %in% c("Swansea")) {
    return("Swansea City")
  } else if(v %in% c("Watford FC")) {
    return("Watford")
  } else if(v %in% c("West Brom")) {
    return("West Bromwich Albion")
  } else if(v %in% c("West Ham")) {
    return("West Ham United")
  } else if(v %in% c("Wigan")) {
    return("Wigan Athletic")
  } else if(v %in% c("Wimbledon FC")) {
    return("Wimbledon")
  } else if(v %in% c("Wolves")) {
    return("Wolverhampton Wanderers")
  }
  return(v)
}
```


```{r}
# Reshaping the json array into a frame
transfer_data <- transfer_data_raw %>% 
  gather_array %>% 
  spread_values(
    season = jnumber("season"),
    club = jstring("club"),
    arrivals = jstring("arrival"),
    departures = jstring("departures"),
    income = jstring("income"),
    expenditure = jstring("expenditure"),
    balance = jstring("balance")
  ) %>% 
  # cleaning columns that are meant to be numbers by removing non numeric characters
  # and converting them to number type
  mutate(
    club = mapply(normalise_club_name, club),
    income_m = mapply(parse_number_value, income),
    expenditure_m = mapply(parse_number_value, expenditure),
    balance_m = mapply(parse_number_value, balance),
    arrivals = parse_number(arrivals),
    departures = parse_number(departures),
  ) %>% 
  select(season, club, income_m, expenditure_m, balance_m, arrivals, departures)

transfer_data$income_m[is.na(transfer_data$income_m)] <- 0
transfer_data$expenditure_m[is.na(transfer_data$expenditure_m)] <- 0

epl_tables <- epl_tables_raw %>% 
  gather_array %>% 
  spread_values(
    season = jnumber("season"),
    position = jstring("position"),
    club = jstring("club"),
    played = jstring("played"),
    won = jstring("won"),
    drawn = jstring("drawn"),
    lost = jstring("lost"),
    goals = jstring("goals"),
    goal_diff = jstring("goals_diff"),
    points = jstring("points")
  ) %>% 
  separate(goals, c("goals_for", "goals_against"), ":") %>% 
  mutate(
    position = parse_number(position),
    club = mapply(normalise_club_name, club),
    played = parse_number(played),
    won = parse_number(won),
    drawn = parse_number(drawn),
    lost = parse_number(lost),
    goals_for = parse_number(goals_for),
    goals_against = parse_number(goals_against),
    goal_diff = parse_number(goal_diff),
    points = parse_number(points)
  ) %>% 
  select(season, position, club, played, won, drawn, lost, goals_for, goals_against, goal_diff, points)

sorted_tables <- epl_tables %>% 
  group_by(season) %>% 
  arrange(position, .by_group = TRUE)

sorted_tables %>% filter(season == 1992)

write_csv(sorted_tables, file = "Income_expenditure_table_posItions_1992-2021.csv")
```

After processing the raw JSON data from Transfermarkt, I created a comprehensive Premier League dataset spanning from 1992 to 2021. I wrote two helper functions to clean up the data: one to parse monetary values correctly (handling those pesky "k" suffixes and converting them to millions), and another to standardize club names across all seasons (converting shorthand names like "Man Utd" to "Manchester United"). With these tools in place, I restructured the transfer data JSON, extracting key financial metrics like income, expenditure, and player movement statistics for each club. I did the same with the league tables, pulling season standings, match performance stats, and goal information.

After normalizing the club names, I converted all text values to their proper numeric format, making sure to handle any missing values by replacing them with zeros where appropriate. I then arranged the league tables by position within each season to maintain the correct hierarchy. To verify everything was working correctly, I did a quick check on the 1992 season data. Finally, I saved the cleaned and formatted dataset to a CSV file for easier access in future analysis steps. This preparation work creates a foundation for exploring relationships between financial investments and on-field performance across the Premier League era.

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(tidyjson)
library(dplyr)
library(knitr)
library(tidymodels)
library(prophet)
library(caret)
library(ranger)

data <- read.csv(file = "Income_expenditure_table_posItIons_1992-2021.csv")
```

## Permier League Winners

First, let me look at all of the title-winning teams and how many times they've won it.

```{r echo=FALSE}
winners <- data %>% 
  group_by(season) %>% 
  arrange(position, .by_group = TRUE) %>% 
  filter(position == 1)

winners_summary <- winners %>% 
  group_by(club) %>% 
  summarise(
    total_wins = n(),
    total_spend = sum(expenditure_m),
    total_spend_fmt = formatC(total_spend, format = "f", big.mark = ",", digits = 1),
    average_expenditure = mean(expenditure_m),
  ) %>% 
  arrange(desc(total_wins))

ggplot(winners_summary, aes(x = reorder(club, total_wins), y = total_wins)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = total_wins), colour = "white", hjust = 2) +
  theme_light() +
  coord_flip() +
  labs(x = "Club", y = "Times won")
```

Manchester United has won 13 Premier League titles in 30 seasons, cementing their historic dominance. One now may look at how much each club spent on average and in total for their title victories.


```{r echo=FALSE}
kable(winners_summary %>% select(club, total_spend, average_expenditure), caption = "Expenditure for each title win", col.names = c("Club names", "Total Expenditure (M) EUR", "Average per title (M) EUR"))
```

### Expenditure vs. League Position

Now spending a lot of money does not guarantee a better league position. The scatter plot below shows where each team finished in terms of expenditure during the season.

```{r}
total_spend <- winners %>% 
  group_by(club) %>% 
  summarise(
    total_wins = n(),
    total_spend = sum(expenditure_m),
    total_spend_fmt = formatC(total_spend, format = "f", big.mark = ",", digits = 1),
    average_expenditure = mean(expenditure_m),
    total_income = sum(income_m),
    average_income = mean(income_m),
    net_spend = total_income - total_spend,
    average_net_spend = average_income - average_expenditure,
    total_arrivals = sum(arrivals)
  ) %>% 
  arrange(desc(total_wins))
```

```{r echo=FALSE}
ggplot(data, aes(expenditure_m, position)) +
  geom_point(colour = "steelblue") +
  theme_light() +
  labs(x = "Expenditure (M) EUR", y = "Position")
```

### Spending over time

Now to see how has spending in the Premier League changed over time?

```{r echo=FALSE}
spend_over_time <- data %>% 
  group_by(season) %>% 
  summarise(total_expenditure = sum(expenditure_m))

ggplot(spend_over_time, aes(x = season, y = total_expenditure)) +
  geom_line(colour = "steelblue") +
  geom_point(shape=21, color="steelblue", fill="white", size=2) +
  theme_light() +
  labs(x = "Season", y = "Expenditure (M) EUR")
```



## Modelling

First, let me create a time series model that can analyze the spending trends and title wins:

```{r}
# Load necessary libraries for Premier League predictions
library(tidyverse)
library(forecast)
library(tseries)
library(ggplot2)

# 1. Data preparation for time series forecasting
data <- data %>%
  mutate(
    season_year = as.numeric(substr(season, 1, 4)),
    relative_expenditure = expenditure_m / mean(expenditure_m, na.rm = TRUE)
  )

# 2. Create time series for each club's expenditure and position
create_club_ts <- function(club_name) {
  # Extract data for this club
  club_data <- data %>%
    filter(club == club_name) %>%
    arrange(season_year)
  
  # Check if we have enough data (at least 5 seasons)
  if(nrow(club_data) < 5) {
    return(NULL)
  }
  
  # Create time series objects
  exp_ts <- ts(club_data$expenditure_m, 
               start = min(club_data$season_year), 
               frequency = 1)
  
  pos_ts <- ts(club_data$position, 
               start = min(club_data$season_year), 
               frequency = 1)
  
  return(list(
    club = club_name,
    expenditure_ts = exp_ts,
    position_ts = pos_ts,
    last_year = max(club_data$season_year)
  ))
}
```

```{r}
# Get clubs with sufficient data
clubs_with_history <- data %>%
  group_by(club) %>%
  summarize(seasons = n()) %>%
  filter(seasons >= 5) %>%
  pull(club)

# Create time series for each club
club_ts_list <- lapply(clubs_with_history, create_club_ts)
names(club_ts_list) <- clubs_with_history
```

Building ARIMA Forecasting Models

ARIMA models are well-suited for our analysis as they can capture the complex temporal dynamics of team performance and financial investment. The forecast package in R provides robust implementations of these models

```{r}
# 3. Build ARIMA models and generate forecasts
forecast_club <- function(club_ts, horizon = 20) {
  if(is.null(club_ts)) {
    return(NULL)
  }
  
  # Fit ARIMA models
  tryCatch({
    exp_model <- auto.arima(club_ts$expenditure_ts)
    pos_model <- auto.arima(club_ts$position_ts)
    
    # Generate forecasts
    exp_forecast <- forecast(exp_model, h = horizon)
    pos_forecast <- forecast(pos_model, h = horizon)
    
    # Create forecast dataframe
    forecast_years <- (club_ts$last_year + 1):(club_ts$last_year + horizon)
    forecast_seasons <- paste0(forecast_years, "/", substr(forecast_years + 1, 3, 4))
    
    forecast_df <- data.frame(
      club = club_ts$club,
      season = forecast_seasons,
      year = forecast_years,
      forecasted_expenditure = as.numeric(exp_forecast$mean),
      forecasted_position = as.numeric(pos_forecast$mean),
      exp_lower_95 = as.numeric(exp_forecast$lower[,2]),
      exp_upper_95 = as.numeric(exp_forecast$upper[,2]),
      pos_lower_95 = as.numeric(pos_forecast$lower[,2]),
      pos_upper_95 = as.numeric(pos_forecast$upper[,2])
    )
    
    return(list(
      club = club_ts$club,
      exp_model = exp_model,
      pos_model = pos_model,
      exp_forecast = exp_forecast,
      pos_forecast = pos_forecast,
      forecast_df = forecast_df
    ))
  }, error = function(e) {
    message(paste("Error forecasting for", club_ts$club, ":", e$message))
    return(NULL)
  })
}

# Generate forecasts for all clubs
club_forecasts <- lapply(club_ts_list, forecast_club)
names(club_forecasts) <- clubs_with_history
```

The auto.arima() function automatically selects the optimal ARIMA parameters based on information criteria, fitting the best model to each club's historical expenditure and position data.


Combining Forecasts and Determining Future Champions
With individual club forecasts generated, we can now combine them and determine the most likely Premier League champions for each future season:

```{r}
# 4. Combine all forecasts
all_forecasts <- do.call(rbind, lapply(club_forecasts, function(fc) {
  if(!is.null(fc)) {
    return(fc$forecast_df)
  } else {
    return(NULL)
  }
}))

# 5. Determine champions for each future season
predicted_champions <- all_forecasts %>%
  group_by(season) %>%
  # Get club with lowest predicted position (best)
  arrange(forecasted_position, .by_group = TRUE) %>%
  slice(1) %>%
  select(season, year, club, forecasted_expenditure, forecasted_position)
```


Advanced Model Validation
To ensure our forecasts are reliable, we should validate our time series models against alternative approaches. One method is to create a regression model that directly relates expenditure to league position:

```{r}
# 1. Check for problematic values in expenditure_m
summary(data$expenditure_m)
sum(data$expenditure_m <= 0, na.rm = TRUE)  # Count zero/negative values

# 2. Handle zero/negative expenditures (if any exist)
data_clean <- data %>%
  filter(expenditure_m > 0) %>%  # Remove rows with zero/negative spending
  mutate(log_expenditure = log(expenditure_m))  # Create logged variable

# 3. Verify clean data
sum(is.infinite(data_clean$log_expenditure))  # Should return 0
sum(is.na(data_clean$log_expenditure))  # Check for remaining NA values

# 4. Build model with clean data
position_model <- lm(position ~ log_expenditure, 
                    data = data_clean,
                    na.action = na.omit)

summary(position_model)


# Generate position predictions based on expenditure
all_forecasts$model_position <- predict(
  position_model,
  newdata = data.frame(
    log_expenditure = log(all_forecasts$forecasted_expenditure)
  )
)

# Compare the two approaches
comparison <- all_forecasts %>%
  select(club, season, forecasted_expenditure, forecasted_position, model_position) %>%
  mutate(position_difference = forecasted_position - model_position)
```

This comparison between time series forecasts and regression-based predictions helps validate our methodology and identify potential discrepancies

Implementing Machine Learning Enhancement
For more sophisticated predictions, we can incorporate machine learning approaches using supervised learning models

```{r}
# Enhanced prediction with machine learning features
library(caret)
library(randomForest)

# Create lagged features for time series machine learning
enhance_data <- data %>%
  group_by(club) %>%
  arrange(season_year) %>%
  mutate(
    prev_position = lag(position),
    prev_expenditure = lag(expenditure_m),
    position_trend = position - prev_position,
    is_previous_winner = ifelse(lag(position) == 1, 1, 0)
  ) %>%
  ungroup() %>%
  filter(!is.na(prev_position))

# Train random forest model
rf_model <- randomForest(
  position ~ expenditure_m + prev_position + prev_expenditure + position_trend + is_previous_winner,
  data = enhance_data,
  ntree = 500
)

# Function to recursively predict future positions
predict_future_positions <- function(club_data, expenditure_forecast, years = 20) {
  results <- data.frame()
  current_position <- tail(club_data$position, 1)
  current_expenditure <- tail(club_data$expenditure_m, 1)
  
  for (i in 1:years) {
    next_expenditure <- expenditure_forecast[i]
    
    pred_data <- data.frame(
      expenditure_m = next_expenditure,
      prev_position = current_position,
      prev_expenditure = current_expenditure,
      position_trend = 0,  # Will be updated
      is_previous_winner = ifelse(current_position == 1, 1, 0)
    )
    
    # Predict position
    next_position <- predict(rf_model, pred_data)
    position_trend <- next_position - current_position
    
    # Store results
    results <- rbind(results, data.frame(
      year = max(club_data$season_year) + i,
      forecasted_position = next_position,
      forecasted_expenditure = next_expenditure
    ))
    
    # Update for next iteration
    current_position <- next_position
    current_expenditure <- next_expenditure
    pred_data$position_trend <- position_trend
  }
  
  return(results)
}
```


Visualizing the Forecasts
Visualizations help interpret complex forecast results:

```{r}
# Plot predicted champions
ggplot(predicted_champions, aes(x = season, y = reorder(club, -forecasted_position))) +
  geom_point(aes(size = forecasted_expenditure), color = "steelblue") +
  theme_light() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = "Predicted Premier League Champions (2022-2042)",
    x = "Season",
    y = "Club",
    size = "Forecasted Expenditure (M EUR)"
  )

# Show expenditure forecasts for top clubs
top_clubs <- head(clubs_with_history, 6)
top_forecasts <- all_forecasts %>%
  filter(club %in% top_clubs)

ggplot(top_forecasts, aes(x = year, y = forecasted_expenditure, color = club)) +
  geom_line() +
  geom_ribbon(aes(ymin = exp_lower_95, ymax = exp_upper_95, fill = club), alpha = 0.2, color = NA) +
  theme_light() +
  labs(
    title = "Expenditure Forecasts for Top Premier League Clubs",
    x = "Season",
    y = "Forecasted Expenditure (M EUR)"
  )
```

Implementation of LSTM Neural Networks
For capturing complex non-linear relationships in time series data, we can implement Long Short-Term Memory (LSTM) networks, which have proven effective for time series forecasting

```{r}
# LSTM implementation for Premier League forecasting
library(keras)
library(tensorflow)

# Prepare data for LSTM
prepare_lstm_data <- function(ts_data, look_back = 5) {
  x <- y <- list()
  for (i in 1:(length(ts_data) - look_back)) {
    x[[i]] <- ts_data[i:(i + look_back - 1)]
    y[[i]] <- ts_data[i + look_back]
  }
  return(list(
    x = array(unlist(x), dim = c(length(x), look_back, 1)),
    y = unlist(y)
  ))
}

# Create and train LSTM model for a single club
train_lstm_model <- function(club_name, look_back = 5) {
  club_data <- data %>% filter(club == club_name)
  if (nrow(club_data) < 10) return(NULL)  # Need sufficient data
  
  # Scale the data
  scale_factors <- c(mean(club_data$expenditure_m), sd(club_data$expenditure_m))
  scaled_data <- (club_data$expenditure_m - scale_factors[1]) / scale_factors[2]
  
  # Prepare sequences
  lstm_data <- prepare_lstm_data(scaled_data, look_back)
  
  # Define model
  model <- keras_model_sequential() %>%
    layer_lstm(units = 50, input_shape = c(look_back, 1), return_sequences = TRUE) %>%
    layer_dropout(rate = 0.2) %>%
    layer_lstm(units = 50, return_sequences = FALSE) %>%
    layer_dropout(rate = 0.2) %>%
    layer_dense(units = 1)
  
  # Compile model
  model %>% compile(
    loss = "mean_squared_error",
    optimizer = "adam"
  )
  
  # Train model
  history <- model %>% fit(
    lstm_data$x, lstm_data$y,
    epochs = 100,
    batch_size = 1,
    verbose = 0
  )
  
  return(list(
    model = model,
    scale_factors = scale_factors,
    look_back = look_back
  ))
}
```
This LSTM implementation captures the sequential nature of Premier League performance data, potentially offering more accurate forecasts than traditional time series methods.



Forecasting Results and Conclusions
Based on our comprehensive time series analysis, we can generate a table of predicted Premier League champions for the next 20 seasons:

```{r}
# Display predicted champions table
kable(predicted_champions, 
      col.names = c("Season", "Year", "Predicted Champion", "Forecasted Expenditure (M EUR)", "Forecasted Position"),
      caption = "Predicted Premier League Champions for Next 20 Seasons")
```

## Testing code 2

```{r}
# Load necessary libraries
library(tidyverse)
library(forecast)
library(lubridate)

# Read and prepare the data
data <- read.csv(file = "92-21-income_expenditure_table_positions.csv")

# Aggregate total expenditure per season
spend_over_time <- data %>% 
  group_by(season) %>% 
  summarise(total_expenditure = sum(expenditure_m)) %>% 
  arrange(season)

# Extract the starting year from the season field (e.g., "1992/93" becomes 1992)
spend_over_time <- spend_over_time %>% 
  mutate(year = as.numeric(substr(season, 1, 4)))

# Create a time series object from the aggregated data
ts_expenditure <- ts(spend_over_time$total_expenditure, 
                     start = min(spend_over_time$year), 
                     frequency = 1)

# Fit an ARIMA model automatically
fit_arima <- auto.arima(ts_expenditure)
print(summary(fit_arima))  # View model summary

# Forecast the next 20 seasons / years
forecast_expenditure <- forecast(fit_arima, h = 20)

# Plot the forecast
plot(forecast_expenditure, main="ARIMA Forecast: Total Expenditure for Next 20 Seasons")

# Optionally, print forecast details
print(forecast_expenditure)
```

```{r}
# Load necessary libraries for machine learning and plotting
library(randomForest)
library(ggplot2)

# Use the prepared spend_over_time data with 'year' and 'total_expenditure'
model_data <- spend_over_time %>% select(year, total_expenditure)

# Fit a random forest regression model
rf_model <- randomForest(total_expenditure ~ year, data = model_data, ntree = 500, importance = TRUE)
print(rf_model)

# Create a new data frame for predictions for the next 20 years
last_year <- max(model_data$year)
future_years <- data.frame(year = seq(last_year + 1, last_year + 20, by = 1))

# Predict future total expenditure using the random forest model
future_years$predicted_expenditure <- predict(rf_model, newdata = future_years)

# Plot historical data alongside the forecasted values
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "red", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "red", linetype = "dashed") +
  labs(title = "Random Forest Forecast: Total Expenditure (Historical vs. Future)",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

# Optionally, display the future predictions
print(future_years)
```

```{r}
# Load libraries
library(ggplot2)

# Fit a linear regression model
lm_model <- lm(total_expenditure ~ year, data = model_data)
print(summary(lm_model))  # Model summary

# Predict for the next 20 years
future_years$predicted_expenditure <- predict(lm_model, newdata = future_years)

# Plot historical and predicted data
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "green", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "green", linetype = "dashed") +
  labs(title = "Linear Regression Forecast: Total Expenditure",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

print(future_years)
```

```{r}
# Load necessary libraries
library(e1071)

# Fit an SVM model for regression
svm_model <- svm(total_expenditure ~ year, data = model_data, type = "eps-regression")
summary(svm_model)

# Predict future expenditures
future_years$predicted_expenditure <- predict(svm_model, newdata = future_years)

# Plot historical and predicted data
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "purple", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "purple", linetype = "dashed") +
  labs(title = "SVM Forecast: Total Expenditure",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

print(future_years)
```

```{r}
# Load necessary libraries
library(gbm)

# Fit a GBM model for regression
gbm_model <- gbm(total_expenditure ~ year, data = model_data, distribution = "gaussian", n.trees = 1000, shrinkage = 0.01)
summary(gbm_model)

# Predict future expenditures
future_years$predicted_expenditure <- predict(gbm_model, newdata = future_years, n.trees = 1000)

# Plot historical and predicted data
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "orange", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "orange", linetype = "dashed") +
  labs(title = "GBM Forecast: Total Expenditure",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

print(future_years)
```

```{r}
# Load necessary libraries
library(nnet)

# Fit a neural network model for regression
nn_model <- nnet(total_expenditure ~ year, data = model_data, size = 5, linout = TRUE)
summary(nn_model)

# Predict future expenditures
future_years$predicted_expenditure <- predict(nn_model, newdata = future_years)

# Plot historical and predicted data
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "red", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "red", linetype = "dashed") +
  labs(title = "Neural Network Forecast: Total Expenditure",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

print(future_years)
```