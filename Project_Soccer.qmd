---
title: "English Premier League (1992/93 - 2021/22) Analysis"
author: "Namit Shrivastava"
date: "2024-04-13"
format: pdf
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
installed.packages(c("tidyverse"))
```

## Data Extraction

```{r}
# Data Extraction Process for Premier League Data
# This code demonstrates how to scrape Transfermarkt data and save it to CSV

# Load necessary libraries for web scraping and data manipulation
library(rvest)
library(dplyr)
library(tidyr)
library(readr)
```

```{r}
# Function to extract season data from Transfermarkt
extract_season_data <- function(season_year) {
  # Construct URL for the given season (format: 1992 for 1992/93 season)
  base_url <- paste0("https://www.transfermarkt.co.uk/premier-league/tabelle/wettbewerb/GB1?saison_id=", season_year)
  
  # Add delay to be respectful to the website
  Sys.sleep(2)
  
  # Read and parse the webpage
  page <- tryCatch({
    read_html(base_url)
  }, error = function(e) {
    message("Error reading URL: ", base_url, " - ", e$message)
    return(NULL)
  })
  
  if(is.null(page)) return(NULL)
  
  # Extract table data
  table_data <- tryCatch({
    tables <- page %>% html_nodes("table.items") %>% html_table()
    if(length(tables) > 0) tables[[1]] else NULL
  }, error = function(e) {
    message("Error extracting table: ", e$message)
    return(NULL)
  })
  
  if(is.null(table_data)) return(NULL)
  
  # Print column names to debug
  print(paste("Original columns:", paste(names(table_data), collapse=", ")))
  
  # Clean column names and data - adjust the column names based on the actual structure
  if(ncol(table_data) >= 10) {
    names(table_data)[1:10] <- c("position", "club", "matches", "wins", "draws", "losses", 
                                 "goals_for", "goals_against", "goal_difference", "points")
    
    # Clean the club names (remove rank numbers if they exist)
    table_data$club <- gsub("^\\d+\\s", "", table_data$club)
    
    # Remove unnecessary rows and columns
    table_data <- table_data %>%
      filter(!is.na(position) & position != "") %>%
      select(position, club, points)
  } else {
    message("Table structure is unexpected. Number of columns: ", ncol(table_data))
    print(head(table_data))
    return(NULL)
  }
  
  # Extract transfer expenditure from separate page
  transfer_url <- paste0("https://www.transfermarkt.co.uk/premier-league/transfers/wettbewerb/GB1/plus/?saison_id=", season_year)
  
  transfer_page <- tryCatch({
    read_html(transfer_url)
  }, error = function(e) {
    message("Error reading transfer URL: ", transfer_url, " - ", e$message)
    return(NULL)
  })
  
  if(is.null(transfer_page)) {
    # If we can't get transfer data, return just the table data with zero expenditure
    return(table_data %>% 
             mutate(
               expenditure_m = 0,
               season = paste0(season_year, "/", substr(season_year + 1, 3, 4))
             )
    )
  }
  
  # Extract club expenditure data
  transfer_data <- tryCatch({
    transfer_page %>%
      html_nodes(".large-8 .box") %>%
      html_nodes("table") %>%
      html_table()
  }, error = function(e) {
    message("Error extracting transfer tables: ", e$message)
    return(list())
  })
  
  # Process transfer data to extract expenditure
  expenditure_data <- data.frame(
    club = character(),
    expenditure_m = numeric(),
    stringsAsFactors = FALSE
  )
  
  for(i in seq_along(transfer_data)) {
    if(i %% 2 == 1) { # Club transfer tables are at odd indices
      club_name <- tryCatch({
        club_nodes <- transfer_page %>% html_nodes(".large-8 .box h2")
        if(length(club_nodes) >= ceiling(i/2)) {
          club_nodes[ceiling(i/2)] %>% html_text() %>% trimws()
        } else {
          paste("Unknown Club", i)
        }
      }, error = function(e) {
        message("Error extracting club name: ", e$message)
        return(paste("Unknown Club", i))
      })
      
      if(length(transfer_data[[i]]) > 0) {
        # Get expenditure from last row, last column
        exp_col <- ncol(transfer_data[[i]])
        exp_row <- nrow(transfer_data[[i]])
        
        # Check if there are actually rows and columns
        if(exp_row > 0 && exp_col > 0) {
          exp_text <- as.character(transfer_data[[i]][exp_row, exp_col])
          
          # Parse the expenditure value (e.g., "â‚¬10.50m" to 10.5)
          exp_value <- gsub("[^0-9.]", "", exp_text)
          if(exp_value != "") {
            exp_value <- as.numeric(exp_value)
            if(grepl("m", exp_text)) {
              exp_value <- exp_value # Already in millions
            } else if(grepl("k", exp_text)) {
              exp_value <- exp_value / 1000 # Convert thousands to millions
            }
          } else {
            exp_value <- 0
          }
          
          # Add to expenditure data
          expenditure_data <- rbind(expenditure_data, 
                                   data.frame(club = club_name, 
                                             expenditure_m = exp_value,
                                             stringsAsFactors = FALSE))
        }
      }
    }
  }
  
  # Print debug info about the clubs found
  if(nrow(expenditure_data) > 0) {
    print(paste("Extracted expenditure data for", nrow(expenditure_data), "clubs"))
    print(paste("Clubs found:", paste(expenditure_data$club, collapse=", ")))
  } else {
    print("No expenditure data extracted")
  }
  
  # Standardize club names between the two datasets
  # This could be improved with a more robust name matching approach
  if(nrow(expenditure_data) > 0) {
    # Print both club name lists to see differences
    print("League table clubs:")
    print(table_data$club)
    print("Transfer page clubs:")
    print(expenditure_data$club)
    
    # Clean club names to improve matching
    expenditure_data$club <- gsub(" FC", "", expenditure_data$club)
    table_data$club <- gsub(" FC", "", table_data$club)
    
    # Create a mapping table for club names that might differ between the two sources
    club_mapping <- data.frame(
      transfermarkt_name = c("Manchester United", "Manchester City", "Arsenal FC"),
      table_name = c("Man Utd", "Man City", "Arsenal"),
      stringsAsFactors = FALSE
    )
    
    # Apply mapping if needed
    for(i in 1:nrow(club_mapping)) {
      expenditure_data$club[expenditure_data$club == club_mapping$transfermarkt_name[i]] <- 
        club_mapping$table_name[i]
    }
  }
  
  # Join the tables
  season_data <- table_data %>%
    left_join(expenditure_data, by = "club") %>%
    mutate(
      position = as.numeric(position),
      points = as.numeric(points),
      season = paste0(season_year, "/", substr(season_year + 1, 3, 4)),
      expenditure_m = ifelse(is.na(expenditure_m), 0, expenditure_m)
    )
  
  # Final check before returning
  if(nrow(season_data) == 0) {
    message("Warning: No data extracted for season ", season_year)
    return(NULL)
  }
  
  return(season_data)
}
```

```{r}
# Extract data for all Premier League seasons (1992/93 to 2025/26)
all_seasons <- data.frame()
for(year in 1992:2025) {
  cat("Extracting data for season", year, "/", substr(year + 1, 3, 4), "\n")
  season_data <- extract_season_data(year)
  all_seasons <- rbind(all_seasons, season_data)
  
  # Save intermediate results in case of interruption
  write_csv(all_seasons, "premier_league_data_partial.csv")
}
```

```{r}
# Clean and prepare final dataset
final_data <- all_seasons %>%
  # Make sure club names aren't NA
  filter(!is.na(club)) %>%
  # Ensure proper data types
  mutate(
    position = as.numeric(position),
    expenditure_m = as.numeric(expenditure_m),
    points = as.numeric(points)
  ) %>%
  # Sort by season and position
  arrange(season, position) %>%
  select(season, club, position, expenditure_m, points)

# Check for any remaining NAs
na_counts <- colSums(is.na(final_data))
print(paste("NA values by column:", paste(names(na_counts), na_counts, sep=": ", collapse=", ")))

# If there are still NAs, you might want to handle them
if(sum(na_counts) > 0) {
  final_data <- final_data %>%
    # Replace NA expenditures with 0
    mutate(expenditure_m = ifelse(is.na(expenditure_m), 0, expenditure_m))
}

# Save data to CSV
write_csv(final_data, "92-25-income_expenditure_table_positions.csv")

# Display summary of extracted data
cat("Data extraction complete. Saved", nrow(final_data), "records spanning", 
    length(unique(final_data$season)), "seasons with", 
    length(unique(final_data$club)), "unique clubs.\n")

# Preview of the extracted data
head(final_data)
```

```{r echo=FALSE, message=FALSE}
library(tidyverse)
library(tidyjson)
library(dplyr)
library(knitr)
library(tidymodels)
library(prophet)
library(caret)
library(ranger)

data <- read.csv(file = "92-21-income_expenditure_table_positions.csv")
```

## Overview

This analysis examines data from the English Premier League seasons 1992/92 through 2021/22 to investigate the relationship between transfer spending and on-field success. The data was extracted from [Transfermarkt](https://www.transfermarkt.co.uk).



## Permier League Winners

First, let me look at all of the title-winning teams and how many times they've won it.

```{r echo=FALSE}
winners <- data %>% 
  group_by(season) %>% 
  arrange(position, .by_group = TRUE) %>% 
  filter(position == 1)

winners_summary <- winners %>% 
  group_by(club) %>% 
  summarise(
    total_wins = n(),
    total_spend = sum(expenditure_m),
    total_spend_fmt = formatC(total_spend, format = "f", big.mark = ",", digits = 1),
    average_expenditure = mean(expenditure_m),
  ) %>% 
  arrange(desc(total_wins))

ggplot(winners_summary, aes(x = reorder(club, total_wins), y = total_wins)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = total_wins), colour = "white", hjust = 2) +
  theme_light() +
  coord_flip() +
  labs(x = "Club", y = "Times won")
```

Manchester United has won 13 Premier League titles in 30 seasons, cementing their historic dominance. One now may look at how much each club spent on average and in total for their title victories.

```{r echo=FALSE}
kable(winners_summary %>% select(club, total_spend, average_expenditure), caption = "Expenditure for each title win", col.names = c("Club names", "Total Expenditure (M) EUR", "Average per title (M) EUR"))
```

### Expenditure vs. League Position

Spending a lot of money does not guarantee a better league position. The scatter plot below shows where each team finished in terms of expenditure during the season.

```{r echo=FALSE}
ggplot(data, aes(expenditure_m, position)) +
  geom_point(colour = "steelblue") +
  theme_light() +
  labs(x = "Expenditure (M) EUR", y = "Position")
```

### Spending over time

How has spending in the Premier League changed over time?

```{r echo=FALSE}
spend_over_time <- data %>% 
  group_by(season) %>% 
  summarise(total_expenditure = sum(expenditure_m))

ggplot(spend_over_time, aes(x = season, y = total_expenditure)) +
  geom_line(colour = "steelblue") +
  geom_point(shape=21, color="steelblue", fill="white", size=2) +
  theme_light() +
  labs(x = "Season", y = "Expenditure (M) EUR")
```


First, let me create a time series model that can analyze the spending trends and title wins:

```{r}
# Load necessary libraries for Premier League predictions
library(tidyverse)
library(forecast)
library(tseries)
library(ggplot2)

# 1. Data preparation for time series forecasting
data <- data %>%
  mutate(
    season_year = as.numeric(substr(season, 1, 4)),
    relative_expenditure = expenditure_m / mean(expenditure_m, na.rm = TRUE)
  )

# 2. Create time series for each club's expenditure and position
create_club_ts <- function(club_name) {
  # Extract data for this club
  club_data <- data %>%
    filter(club == club_name) %>%
    arrange(season_year)
  
  # Check if we have enough data (at least 5 seasons)
  if(nrow(club_data) < 5) {
    return(NULL)
  }
  
  # Create time series objects
  exp_ts <- ts(club_data$expenditure_m, 
               start = min(club_data$season_year), 
               frequency = 1)
  
  pos_ts <- ts(club_data$position, 
               start = min(club_data$season_year), 
               frequency = 1)
  
  return(list(
    club = club_name,
    expenditure_ts = exp_ts,
    position_ts = pos_ts,
    last_year = max(club_data$season_year)
  ))
}

# Get clubs with sufficient data
clubs_with_history <- data %>%
  group_by(club) %>%
  summarize(seasons = n()) %>%
  filter(seasons >= 5) %>%
  pull(club)

# Create time series for each club
club_ts_list <- lapply(clubs_with_history, create_club_ts)
names(club_ts_list) <- clubs_with_history
```

Building ARIMA Forecasting Models

ARIMA models are well-suited for our analysis as they can capture the complex temporal dynamics of team performance and financial investment. The forecast package in R provides robust implementations of these models

```{r}
# 3. Build ARIMA models and generate forecasts
forecast_club <- function(club_ts, horizon = 20) {
  if(is.null(club_ts)) {
    return(NULL)
  }
  
  # Fit ARIMA models
  tryCatch({
    exp_model <- auto.arima(club_ts$expenditure_ts)
    pos_model <- auto.arima(club_ts$position_ts)
    
    # Generate forecasts
    exp_forecast <- forecast(exp_model, h = horizon)
    pos_forecast <- forecast(pos_model, h = horizon)
    
    # Create forecast dataframe
    forecast_years <- (club_ts$last_year + 1):(club_ts$last_year + horizon)
    forecast_seasons <- paste0(forecast_years, "/", substr(forecast_years + 1, 3, 4))
    
    forecast_df <- data.frame(
      club = club_ts$club,
      season = forecast_seasons,
      year = forecast_years,
      forecasted_expenditure = as.numeric(exp_forecast$mean),
      forecasted_position = as.numeric(pos_forecast$mean),
      exp_lower_95 = as.numeric(exp_forecast$lower[,2]),
      exp_upper_95 = as.numeric(exp_forecast$upper[,2]),
      pos_lower_95 = as.numeric(pos_forecast$lower[,2]),
      pos_upper_95 = as.numeric(pos_forecast$upper[,2])
    )
    
    return(list(
      club = club_ts$club,
      exp_model = exp_model,
      pos_model = pos_model,
      exp_forecast = exp_forecast,
      pos_forecast = pos_forecast,
      forecast_df = forecast_df
    ))
  }, error = function(e) {
    message(paste("Error forecasting for", club_ts$club, ":", e$message))
    return(NULL)
  })
}

# Generate forecasts for all clubs
club_forecasts <- lapply(club_ts_list, forecast_club)
names(club_forecasts) <- clubs_with_history
```

The auto.arima() function automatically selects the optimal ARIMA parameters based on information criteria, fitting the best model to each club's historical expenditure and position data.


Combining Forecasts and Determining Future Champions
With individual club forecasts generated, we can now combine them and determine the most likely Premier League champions for each future season:

```{r}
# 4. Combine all forecasts
all_forecasts <- do.call(rbind, lapply(club_forecasts, function(fc) {
  if(!is.null(fc)) {
    return(fc$forecast_df)
  } else {
    return(NULL)
  }
}))

# 5. Determine champions for each future season
predicted_champions <- all_forecasts %>%
  group_by(season) %>%
  # Get club with lowest predicted position (best)
  arrange(forecasted_position, .by_group = TRUE) %>%
  slice(1) %>%
  select(season, year, club, forecasted_expenditure, forecasted_position)
```


Advanced Model Validation
To ensure our forecasts are reliable, we should validate our time series models against alternative approaches. One method is to create a regression model that directly relates expenditure to league position:

```{r}
# 1. Check for problematic values in expenditure_m
summary(data$expenditure_m)
sum(data$expenditure_m <= 0, na.rm = TRUE)  # Count zero/negative values

# 2. Handle zero/negative expenditures (if any exist)
data_clean <- data %>%
  filter(expenditure_m > 0) %>%  # Remove rows with zero/negative spending
  mutate(log_expenditure = log(expenditure_m))  # Create logged variable

# 3. Verify clean data
sum(is.infinite(data_clean$log_expenditure))  # Should return 0
sum(is.na(data_clean$log_expenditure))  # Check for remaining NA values

# 4. Build model with clean data
position_model <- lm(position ~ log_expenditure, 
                    data = data_clean,
                    na.action = na.omit)

summary(position_model)


# Generate position predictions based on expenditure
all_forecasts$model_position <- predict(
  position_model,
  newdata = data.frame(
    log_expenditure = log(all_forecasts$forecasted_expenditure)
  )
)

# Compare the two approaches
comparison <- all_forecasts %>%
  select(club, season, forecasted_expenditure, forecasted_position, model_position) %>%
  mutate(position_difference = forecasted_position - model_position)
```

This comparison between time series forecasts and regression-based predictions helps validate our methodology and identify potential discrepancies

Implementing Machine Learning Enhancement
For more sophisticated predictions, we can incorporate machine learning approaches using supervised learning models

```{r}
# Enhanced prediction with machine learning features
library(caret)
library(randomForest)

# Create lagged features for time series machine learning
enhance_data <- data %>%
  group_by(club) %>%
  arrange(season_year) %>%
  mutate(
    prev_position = lag(position),
    prev_expenditure = lag(expenditure_m),
    position_trend = position - prev_position,
    is_previous_winner = ifelse(lag(position) == 1, 1, 0)
  ) %>%
  ungroup() %>%
  filter(!is.na(prev_position))

# Train random forest model
rf_model <- randomForest(
  position ~ expenditure_m + prev_position + prev_expenditure + position_trend + is_previous_winner,
  data = enhance_data,
  ntree = 500
)

# Function to recursively predict future positions
predict_future_positions <- function(club_data, expenditure_forecast, years = 20) {
  results <- data.frame()
  current_position <- tail(club_data$position, 1)
  current_expenditure <- tail(club_data$expenditure_m, 1)
  
  for (i in 1:years) {
    next_expenditure <- expenditure_forecast[i]
    
    pred_data <- data.frame(
      expenditure_m = next_expenditure,
      prev_position = current_position,
      prev_expenditure = current_expenditure,
      position_trend = 0,  # Will be updated
      is_previous_winner = ifelse(current_position == 1, 1, 0)
    )
    
    # Predict position
    next_position <- predict(rf_model, pred_data)
    position_trend <- next_position - current_position
    
    # Store results
    results <- rbind(results, data.frame(
      year = max(club_data$season_year) + i,
      forecasted_position = next_position,
      forecasted_expenditure = next_expenditure
    ))
    
    # Update for next iteration
    current_position <- next_position
    current_expenditure <- next_expenditure
    pred_data$position_trend <- position_trend
  }
  
  return(results)
}
```


Visualizing the Forecasts
Visualizations help interpret complex forecast results:

```{r}
# Plot predicted champions
ggplot(predicted_champions, aes(x = season, y = reorder(club, -forecasted_position))) +
  geom_point(aes(size = forecasted_expenditure), color = "steelblue") +
  theme_light() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = "Predicted Premier League Champions (2022-2042)",
    x = "Season",
    y = "Club",
    size = "Forecasted Expenditure (M EUR)"
  )

# Show expenditure forecasts for top clubs
top_clubs <- head(clubs_with_history, 6)
top_forecasts <- all_forecasts %>%
  filter(club %in% top_clubs)

ggplot(top_forecasts, aes(x = year, y = forecasted_expenditure, color = club)) +
  geom_line() +
  geom_ribbon(aes(ymin = exp_lower_95, ymax = exp_upper_95, fill = club), alpha = 0.2, color = NA) +
  theme_light() +
  labs(
    title = "Expenditure Forecasts for Top Premier League Clubs",
    x = "Season",
    y = "Forecasted Expenditure (M EUR)"
  )
```

Implementation of LSTM Neural Networks
For capturing complex non-linear relationships in time series data, we can implement Long Short-Term Memory (LSTM) networks, which have proven effective for time series forecasting

```{r}
# LSTM implementation for Premier League forecasting
library(keras)
library(tensorflow)

# Prepare data for LSTM
prepare_lstm_data <- function(ts_data, look_back = 5) {
  x <- y <- list()
  for (i in 1:(length(ts_data) - look_back)) {
    x[[i]] <- ts_data[i:(i + look_back - 1)]
    y[[i]] <- ts_data[i + look_back]
  }
  return(list(
    x = array(unlist(x), dim = c(length(x), look_back, 1)),
    y = unlist(y)
  ))
}

# Create and train LSTM model for a single club
train_lstm_model <- function(club_name, look_back = 5) {
  club_data <- data %>% filter(club == club_name)
  if (nrow(club_data) < 10) return(NULL)  # Need sufficient data
  
  # Scale the data
  scale_factors <- c(mean(club_data$expenditure_m), sd(club_data$expenditure_m))
  scaled_data <- (club_data$expenditure_m - scale_factors[1]) / scale_factors[2]
  
  # Prepare sequences
  lstm_data <- prepare_lstm_data(scaled_data, look_back)
  
  # Define model
  model <- keras_model_sequential() %>%
    layer_lstm(units = 50, input_shape = c(look_back, 1), return_sequences = TRUE) %>%
    layer_dropout(rate = 0.2) %>%
    layer_lstm(units = 50, return_sequences = FALSE) %>%
    layer_dropout(rate = 0.2) %>%
    layer_dense(units = 1)
  
  # Compile model
  model %>% compile(
    loss = "mean_squared_error",
    optimizer = "adam"
  )
  
  # Train model
  history <- model %>% fit(
    lstm_data$x, lstm_data$y,
    epochs = 100,
    batch_size = 1,
    verbose = 0
  )
  
  return(list(
    model = model,
    scale_factors = scale_factors,
    look_back = look_back
  ))
}
```
This LSTM implementation captures the sequential nature of Premier League performance data, potentially offering more accurate forecasts than traditional time series methods.



Forecasting Results and Conclusions
Based on our comprehensive time series analysis, we can generate a table of predicted Premier League champions for the next 20 seasons:

```{r}
# Display predicted champions table
kable(predicted_champions, 
      col.names = c("Season", "Year", "Predicted Champion", "Forecasted Expenditure (M EUR)", "Forecasted Position"),
      caption = "Predicted Premier League Champions for Next 20 Seasons")
```

## Testing code 2

```{r}
# Load necessary libraries
library(tidyverse)
library(forecast)
library(lubridate)

# Read and prepare the data
data <- read.csv(file = "92-21-income_expenditure_table_positions.csv")

# Aggregate total expenditure per season
spend_over_time <- data %>% 
  group_by(season) %>% 
  summarise(total_expenditure = sum(expenditure_m)) %>% 
  arrange(season)

# Extract the starting year from the season field (e.g., "1992/93" becomes 1992)
spend_over_time <- spend_over_time %>% 
  mutate(year = as.numeric(substr(season, 1, 4)))

# Create a time series object from the aggregated data
ts_expenditure <- ts(spend_over_time$total_expenditure, 
                     start = min(spend_over_time$year), 
                     frequency = 1)

# Fit an ARIMA model automatically
fit_arima <- auto.arima(ts_expenditure)
print(summary(fit_arima))  # View model summary

# Forecast the next 20 seasons / years
forecast_expenditure <- forecast(fit_arima, h = 20)

# Plot the forecast
plot(forecast_expenditure, main="ARIMA Forecast: Total Expenditure for Next 20 Seasons")

# Optionally, print forecast details
print(forecast_expenditure)
```

```{r}
# Load necessary libraries for machine learning and plotting
library(randomForest)
library(ggplot2)

# Use the prepared spend_over_time data with 'year' and 'total_expenditure'
model_data <- spend_over_time %>% select(year, total_expenditure)

# Fit a random forest regression model
rf_model <- randomForest(total_expenditure ~ year, data = model_data, ntree = 500, importance = TRUE)
print(rf_model)

# Create a new data frame for predictions for the next 20 years
last_year <- max(model_data$year)
future_years <- data.frame(year = seq(last_year + 1, last_year + 20, by = 1))

# Predict future total expenditure using the random forest model
future_years$predicted_expenditure <- predict(rf_model, newdata = future_years)

# Plot historical data alongside the forecasted values
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "red", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "red", linetype = "dashed") +
  labs(title = "Random Forest Forecast: Total Expenditure (Historical vs. Future)",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

# Optionally, display the future predictions
print(future_years)
```

```{r}
# Load libraries
library(ggplot2)

# Fit a linear regression model
lm_model <- lm(total_expenditure ~ year, data = model_data)
print(summary(lm_model))  # Model summary

# Predict for the next 20 years
future_years$predicted_expenditure <- predict(lm_model, newdata = future_years)

# Plot historical and predicted data
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "green", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "green", linetype = "dashed") +
  labs(title = "Linear Regression Forecast: Total Expenditure",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

print(future_years)
```

```{r}
# Load necessary libraries
library(e1071)

# Fit an SVM model for regression
svm_model <- svm(total_expenditure ~ year, data = model_data, type = "eps-regression")
summary(svm_model)

# Predict future expenditures
future_years$predicted_expenditure <- predict(svm_model, newdata = future_years)

# Plot historical and predicted data
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "purple", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "purple", linetype = "dashed") +
  labs(title = "SVM Forecast: Total Expenditure",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

print(future_years)
```

```{r}
# Load necessary libraries
library(gbm)

# Fit a GBM model for regression
gbm_model <- gbm(total_expenditure ~ year, data = model_data, distribution = "gaussian", n.trees = 1000, shrinkage = 0.01)
summary(gbm_model)

# Predict future expenditures
future_years$predicted_expenditure <- predict(gbm_model, newdata = future_years, n.trees = 1000)

# Plot historical and predicted data
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "orange", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "orange", linetype = "dashed") +
  labs(title = "GBM Forecast: Total Expenditure",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

print(future_years)
```

```{r}
# Load necessary libraries
library(nnet)

# Fit a neural network model for regression
nn_model <- nnet(total_expenditure ~ year, data = model_data, size = 5, linout = TRUE)
summary(nn_model)

# Predict future expenditures
future_years$predicted_expenditure <- predict(nn_model, newdata = future_years)

# Plot historical and predicted data
ggplot() +
  geom_point(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_line(data = model_data, aes(x = year, y = total_expenditure), color = "blue") +
  geom_point(data = future_years, aes(x = year, y = predicted_expenditure), color = "red", size = 2) +
  geom_line(data = future_years, aes(x = year, y = predicted_expenditure), color = "red", linetype = "dashed") +
  labs(title = "Neural Network Forecast: Total Expenditure",
       x = "Year", y = "Total Expenditure (M EUR)") +
  theme_minimal()

print(future_years)
```