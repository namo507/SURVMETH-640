---
title: "Assignment 1"
output:
  html_document:
    df_print: paged
---

## Setup

```{r results='hide', message=FALSE, warning=FALSE}
library(titanic)
library(caret)
library(pROC)
```

## Data

In this notebook we use the Titanic data that is used on Kaggle (https://www.kaggle.com) as an introductory competition for getting familiar with machine learning. It includes information on a set of Titanic passengers, such as age, sex, ticket class and whether he or she survived the Titanic tragedy.

Source: https://www.kaggle.com/c/titanic/data

```{r}
titanic <- titanic_train
str(titanic)
```

We begin with some minor data preparations. The `lapply()` function is a handy tool if the task is to apply the same transformation (e.g. `as.factor()`) to multiple columns of a data frame.

```{r}
titanic[, c(2:3,5,12)] <- lapply(titanic[, c(2:3,5,12)], as.factor)
```

The `age` variable has some NAs, as a quick and dirty solution we can create a categorized age variable with NAs as an additional factor level.

```{r}
titanic$Age_c <- cut(titanic$Age, 5)
titanic$Age_c <- addNA(titanic$Age_c)
summary(titanic$Age_c)
```

## Train and test set

Next we split the data into a training (80%) and a test (20%) part. This can be done by random sampling with `sample()`.

```{r}
set.seed(9395)
# Add code here

```

## Logistic regression

In this exercise we simply use logistic regression as our prediction method, since we want to focus on the evaluation part. Build a first logit model with `Survived` as the outcome and `Pclass`, `Sex`, `Age_c`, `Fare` and `Embarked` as features.

```{r}

```

A quick look at the coefficients of the first logit model.

```{r}

```

Now, build an additional logit model that uses the same features, but includes at least one interaction or non-linear term.

```{r}

```

Again, summarize the resulting object.

```{r}

```

## Prediction in test set

Given both logit objects, we can generate predicted risk scores/ predicted probabilities of `Survived` in the test set.

```{r}

```

It is often useful to first get an idea of prediction performance independent of specific classification thresholds. Use the `pROC` (or `PRROC`) package to create roc objects for both risk score vectors.

```{r}

```

Now, you can print and plot the resulting `roc` objects.

```{r}

```

In your own words, how would you interpret these ROC curves? What do you think about the ROC-AUCs we observe here?

#### Start text...

#### end

As a next step, we want to predict class membership given the risk scores of our two models. Here we use the default classification threshold, 0.5.

```{r}

```

On this basis, we can use `confusionMatrix()` to get some performance measures for the predicted classes.

```{r}

```

Briefly explain potential limitations when measuring prediction performance as carried out in the last two code chunks.

#### Start text...

#### end
